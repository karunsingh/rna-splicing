{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the splice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'splice.data'\n",
    "with open(fname) as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip().split(',') for x in content]\n",
    "for l in content:\n",
    "    for i in range(len(l)):\n",
    "        l[i] = l[i].strip()\n",
    "raw_data = np.array(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given one 'row' of data, constructs an input and output out of it\n",
    "def getInstance(row):\n",
    "    one_hot = np.zeros((1, 3))\n",
    "    label = row[0]\n",
    "    if label == 'EI':\n",
    "        one_hot[0][0] = 1\n",
    "    elif label == 'IE':\n",
    "        one_hot[0][1] = 1\n",
    "    else:\n",
    "        one_hot[0][2] = 1\n",
    "    orth = np.zeros((len(row[2]), 4))\n",
    "    for i in range(len(row[2])):\n",
    "        c = row[2][i]\n",
    "        if c == 'A':\n",
    "            orth[i][0] = 1\n",
    "        elif c == 'C':\n",
    "            orth[i][1] = 1\n",
    "        elif c == 'G':\n",
    "            orth[i][2] = 1\n",
    "        elif c == 'T':\n",
    "            orth[i][3] = 1\n",
    "        elif c == 'D':\n",
    "            orth[i][0] = 1/3.\n",
    "            orth[i][2] = 1/3.\n",
    "            orth[i][3] = 1/3.\n",
    "        elif c == 'N':\n",
    "            orth[i][0] = 1/4.\n",
    "            orth[i][1] = 1/4.\n",
    "            orth[i][2] = 1/4.\n",
    "            orth[i][3] = 1/4.\n",
    "        elif c == 'S':\n",
    "            orth[i][1] = 1/2.\n",
    "            orth[i][2] = 1/2.\n",
    "        elif c == 'R':\n",
    "            orth[i][0] = 1/2.\n",
    "            orth[i][2] = 1/2.\n",
    "    return orth, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 4, 60) (3190, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(raw_data.shape[0]):\n",
    "    xi, yi = getInstance(raw_data[i])\n",
    "    x.append(xi)\n",
    "    y.append(yi)\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# Shuffle dataset since it's unevenly distributed\n",
    "shuffle_index = np.random.permutation(len(x))\n",
    "x = x[shuffle_index]\n",
    "y = y[shuffle_index]\n",
    "\n",
    "# Conv1D expects channels first\n",
    "x = np.swapaxes(x, 1, 2)\n",
    "print (str(x.shape[0]) + \" examples parsed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, Dropout, MaxPooling1D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()\n",
    "K.set_learning_phase(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(8, 3, input_shape=(None, 60), padding='same', name='conv1'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(16, 3, padding='same', name='conv2'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dense(3, name='fc1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2871 samples, validate on 319 samples\n",
      "Epoch 1/30\n",
      "2871/2871 [==============================] - 4s 1ms/step - loss: 0.9931 - acc: 0.5131 - val_loss: 0.8256 - val_acc: 0.6583\n",
      "Epoch 2/30\n",
      "2871/2871 [==============================] - 1s 206us/step - loss: 0.6208 - acc: 0.7844 - val_loss: 0.4016 - val_acc: 0.8871\n",
      "Epoch 3/30\n",
      "2871/2871 [==============================] - 1s 176us/step - loss: 0.3112 - acc: 0.9094 - val_loss: 0.2267 - val_acc: 0.9310\n",
      "Epoch 4/30\n",
      "2871/2871 [==============================] - 0s 163us/step - loss: 0.1968 - acc: 0.9446 - val_loss: 0.1753 - val_acc: 0.9373\n",
      "Epoch 5/30\n",
      "2871/2871 [==============================] - 0s 161us/step - loss: 0.1477 - acc: 0.9606 - val_loss: 0.1473 - val_acc: 0.9530\n",
      "Epoch 6/30\n",
      "2871/2871 [==============================] - 0s 150us/step - loss: 0.1193 - acc: 0.9666 - val_loss: 0.1414 - val_acc: 0.9498\n",
      "Epoch 7/30\n",
      "2871/2871 [==============================] - 0s 139us/step - loss: 0.0999 - acc: 0.9725 - val_loss: 0.1373 - val_acc: 0.9498\n",
      "Epoch 8/30\n",
      "2871/2871 [==============================] - 0s 138us/step - loss: 0.0877 - acc: 0.9784 - val_loss: 0.1212 - val_acc: 0.9592\n",
      "Epoch 9/30\n",
      "2871/2871 [==============================] - 0s 152us/step - loss: 0.0778 - acc: 0.9829 - val_loss: 0.1301 - val_acc: 0.9561\n",
      "Epoch 10/30\n",
      "2871/2871 [==============================] - 0s 139us/step - loss: 0.0702 - acc: 0.9822 - val_loss: 0.1236 - val_acc: 0.9624\n",
      "Epoch 11/30\n",
      "2871/2871 [==============================] - 0s 129us/step - loss: 0.0643 - acc: 0.9854 - val_loss: 0.1302 - val_acc: 0.9561\n",
      "Epoch 12/30\n",
      "2871/2871 [==============================] - 0s 119us/step - loss: 0.0559 - acc: 0.9885 - val_loss: 0.1384 - val_acc: 0.9467\n",
      "Epoch 13/30\n",
      "2871/2871 [==============================] - 0s 128us/step - loss: 0.0504 - acc: 0.9889 - val_loss: 0.1280 - val_acc: 0.9561\n",
      "Epoch 14/30\n",
      "2871/2871 [==============================] - 0s 112us/step - loss: 0.0467 - acc: 0.9892 - val_loss: 0.1286 - val_acc: 0.9687\n",
      "Epoch 15/30\n",
      "2871/2871 [==============================] - 0s 125us/step - loss: 0.0423 - acc: 0.9934 - val_loss: 0.1301 - val_acc: 0.9561\n",
      "Epoch 16/30\n",
      "2871/2871 [==============================] - 0s 110us/step - loss: 0.0395 - acc: 0.9934 - val_loss: 0.1376 - val_acc: 0.9561\n",
      "Epoch 17/30\n",
      "2871/2871 [==============================] - 0s 102us/step - loss: 0.0361 - acc: 0.9934 - val_loss: 0.1493 - val_acc: 0.9530\n",
      "Epoch 18/30\n",
      "2871/2871 [==============================] - 0s 123us/step - loss: 0.0315 - acc: 0.9948 - val_loss: 0.1414 - val_acc: 0.9530\n",
      "Epoch 19/30\n",
      "2871/2871 [==============================] - 0s 98us/step - loss: 0.0293 - acc: 0.9969 - val_loss: 0.1787 - val_acc: 0.9467\n",
      "Epoch 20/30\n",
      "2871/2871 [==============================] - 0s 95us/step - loss: 0.0270 - acc: 0.9962 - val_loss: 0.1549 - val_acc: 0.9498\n",
      "Epoch 21/30\n",
      "2871/2871 [==============================] - 0s 88us/step - loss: 0.0252 - acc: 0.9962 - val_loss: 0.1741 - val_acc: 0.9530\n",
      "Epoch 22/30\n",
      "2871/2871 [==============================] - 0s 92us/step - loss: 0.0228 - acc: 0.9976 - val_loss: 0.1691 - val_acc: 0.9498\n",
      "Epoch 23/30\n",
      "2871/2871 [==============================] - 0s 76us/step - loss: 0.0214 - acc: 0.9965 - val_loss: 0.2034 - val_acc: 0.9404\n",
      "Epoch 24/30\n",
      "2871/2871 [==============================] - 0s 80us/step - loss: 0.0198 - acc: 0.9976 - val_loss: 0.1689 - val_acc: 0.9467\n",
      "Epoch 25/30\n",
      "2871/2871 [==============================] - 0s 94us/step - loss: 0.0188 - acc: 0.9979 - val_loss: 0.1870 - val_acc: 0.9498\n",
      "Epoch 26/30\n",
      "2871/2871 [==============================] - 0s 77us/step - loss: 0.0170 - acc: 0.9993 - val_loss: 0.1740 - val_acc: 0.9498\n",
      "Epoch 27/30\n",
      "2871/2871 [==============================] - 0s 84us/step - loss: 0.0157 - acc: 0.9990 - val_loss: 0.1718 - val_acc: 0.9467\n",
      "Epoch 28/30\n",
      "2871/2871 [==============================] - 0s 102us/step - loss: 0.0160 - acc: 0.9990 - val_loss: 0.1886 - val_acc: 0.9498\n",
      "Epoch 29/30\n",
      "2871/2871 [==============================] - 0s 99us/step - loss: 0.0138 - acc: 0.9990 - val_loss: 0.2208 - val_acc: 0.9436\n",
      "Epoch 30/30\n",
      "2871/2871 [==============================] - 0s 87us/step - loss: 0.0130 - acc: 0.9990 - val_loss: 0.2153 - val_acc: 0.9498\n"
     ]
    }
   ],
   "source": [
    "callbacks = []\n",
    "#callbacks.append(TensorBoard(write_graph=False, histogram_freq=1, write_grads=False, write_images=False))\n",
    "\n",
    "model.fit(x, y, epochs=30, batch_size=32, validation_split=0.1, shuffle=True, callbacks=callbacks)\n",
    "K.set_learning_phase(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualizeLayer(layer_name, filter_index):\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    print (layer_output)\n",
    "    #loss = K.mean(layer_output[:, :, filter_index])\n",
    "    loss = K.mean(model.output[:, :, filter_index])\n",
    "    input_img = model.input\n",
    "    # compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    #grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "    # we start from a gray image with some noise\n",
    "    input_img_data = np.zeros((1, 4, 60))\n",
    "    input_img_data[:] = 0.25\n",
    "    # run gradient ascent for 20 steps\n",
    "    step = 1\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        \n",
    "        #print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            # break\n",
    "            pass\n",
    "    input_img_data[0] /= np.linalg.norm(input_img_data[0], 1, axis=0)\n",
    "    input_img_data = np.clip(input_img_data, 0, 1)\n",
    "    plt.imshow(input_img_data[0], cmap='viridis')\n",
    "    plt.xticks(np.arange(60), np.arange(60)+1)\n",
    "    plt.yticks(np.arange(4), ('A', 'C', 'G', 'T'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv1_4/add:0\", shape=(?, ?, 8), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2UAAABaCAYAAAA4sv62AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17409f169e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualizeLayer('conv1', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 3)\n",
      "Tensor(\"gradients_64/conv1_4/convolution/ExpandDims_grad/Reshape:0\", shape=(?, ?, 60), dtype=float32)\n",
      "Label is 2\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAAAwCAYAAAAIJQs/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17404456630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1\n",
    "print (model.output.shape)\n",
    "loss = K.mean(model.output[:, :, np.argmax(y[index])])\n",
    "input_img = model.input\n",
    "grads = K.gradients(loss, input_img)[0]\n",
    "print (grads)\n",
    "iterate = K.function([input_img], [loss, grads])\n",
    "input_img_data = np.zeros((1, 4, 60))\n",
    "input_img_data[0,:] = x[index]\n",
    "loss_value, grads_value = iterate([input_img_data])\n",
    "\n",
    "print (\"Label is \" + str(np.argmax(y[index])))\n",
    "g = grads_value[0] * x[index]\n",
    "g = np.sum(g, axis=0).reshape(1, 60)\n",
    "def sequenceFromOneHot(s):\n",
    "    s = s.T\n",
    "    l = []\n",
    "    for i in range(len(s)):\n",
    "        if s[i][0] == 1.:\n",
    "            l.append('A')\n",
    "        elif s[i][1] == 1.:\n",
    "            l.append('C')\n",
    "        elif s[i][2] == 1.:\n",
    "            l.append('G')\n",
    "        elif s[i][3] == 1.:\n",
    "            l.append('T')\n",
    "        elif s[i][0] == 1/3. and s[i][2] == 1/3. and s[i][3] == 1/3.:\n",
    "            l.append('D')\n",
    "        elif s[i][0] == 1/4. and s[i][1] == 1/4. and s[i][2] == 1/4. and s[i][3] == 1/4.:\n",
    "            l.append('N')\n",
    "        elif s[i][1] == 1/2. and s[i][2] == 1/2.:\n",
    "            l.append('S')\n",
    "        elif s[i][0] == 1/2. and s[i][2] == 1/2.:\n",
    "            l.append('R')\n",
    "    return l\n",
    "plt.xticks( np.arange(60), sequenceFromOneHot(x[index]) )\n",
    "plt.yticks([])\n",
    "plt.imshow(g, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 8]\n"
     ]
    }
   ],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print (fig_size)\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  1.  0.]] [[[  2.41259013e-08   9.99948621e-01   5.13993073e-05]]]\n",
      "5.13993e-05\n",
      "[[[  2.60705182e-08   9.99937773e-01   6.22441148e-05]]]\n",
      "6.22441e-05\n",
      "[[[  2.87611090e-08   9.99922633e-01   7.73485372e-05]]]\n",
      "7.73485e-05\n",
      "[[[  3.24939897e-08   9.99898672e-01   1.01319609e-04]]]\n",
      "0.00010132\n",
      "[[[  3.81263341e-08   9.99855638e-01   1.44300167e-04]]]\n",
      "0.0001443\n",
      "[[[  4.78713780e-08   9.99761283e-01   2.38758104e-04]]]\n",
      "0.000238758\n",
      "[[[  6.97509677e-08   9.99450743e-01   5.49164950e-04]]]\n",
      "0.000549165\n",
      "[[[  1.70917033e-07   9.96487021e-01   3.51292174e-03]]]\n",
      "0.00351292\n",
      "[[[  3.04796004e-07   3.13053583e-03   9.96869147e-01]]]\n",
      "0.996869\n",
      "[[[  3.26829230e-08   1.05160291e-06   9.99998927e-01]]]\n",
      "['A', 'A', 'G', 'C', 'C', 'A', 'G', 'A', 'T', 'A', 'T', 'G', 'T', 'C', 'T', 'G', 'T', 'G', 'T', 'T', 'C', 'T', 'C', 'T', 'T', 'T', 'G', 'C', 'A', 'G', 'T', 'A', 'C', 'T', 'G', 'A', 'A', 'G', 'A', 'T', 'A', 'A', 'C', 'A', 'G', 'C', 'C', 'A', 'G', 'G', 'G', 'A', 'G', 'G', 'A', 'C', 'A', 'A', 'G', 'C']\n",
      "['A', 'A', 'G', 'C', 'C', 'A', 'G', 'A', 'T', 'A', 'T', 'G', 'T', 'C', 'T', 'G', 'T', 'G', 'T', 'T', 'C', 'T', 'C', 'T', 'T', 'T', 'G', 'C', 'A', 'G', 'T', 'A', 'C', 'T', 'G', 'A', 'A', 'G', 'A', 'T', 'A', 'A', 'C', 'A', 'G', 'C', 'C', 'A', 'G', 'G', 'G', 'A', 'G', 'G', 'A', 'C', 'A', 'A', 'G', 'C']\n"
     ]
    }
   ],
   "source": [
    "# Perturbation:\n",
    "index = 0\n",
    "label = y[index]\n",
    "prediction = model.predict(np.array([x[index]]))\n",
    "print (label, prediction)\n",
    "e = np.array(x[index])\n",
    "target = 2\n",
    "i = 0\n",
    "\n",
    "loss = K.mean(model.output[:, :, target])\n",
    "input_img = model.input\n",
    "grads = K.gradients(loss, input_img)[0]\n",
    "iterate = K.function([input_img], [loss, grads])\n",
    "input_img_data = np.zeros((1, 4, 60))\n",
    "\n",
    "step = 10.\n",
    "\n",
    "while True:\n",
    "    i += 1\n",
    "    input_img_data[0,:] = e\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    e += grads_value[0] * step\n",
    "    print(loss_value)\n",
    "    print (model.predict(np.array([e])))\n",
    "    if (loss_value > 0.99):\n",
    "        break\n",
    "print (sequenceFromOneHot(x[index]))\n",
    "en = np.argmax(e, axis=0)\n",
    "new_seq = []\n",
    "for i in en:\n",
    "    if i == 0:\n",
    "        new_seq.append('A')\n",
    "    elif i == 1:\n",
    "        new_seq.append('C')\n",
    "    elif i == 2:\n",
    "        new_seq.append('G')\n",
    "    else:\n",
    "        new_seq.append('T')\n",
    "print (new_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
