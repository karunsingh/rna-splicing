{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the splice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'splice.data'\n",
    "with open(fname) as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip().split(',') for x in content]\n",
    "for l in content:\n",
    "    for i in range(len(l)):\n",
    "        l[i] = l[i].strip()\n",
    "raw_data = np.array(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given one 'row' of data, constructs an input and output out of it\n",
    "def getInstance(row):\n",
    "    one_hot = np.zeros((1, 3))\n",
    "    label = row[0]\n",
    "    if label == 'EI':\n",
    "        one_hot[0][0] = 1\n",
    "    elif label == 'IE':\n",
    "        one_hot[0][1] = 1\n",
    "    else:\n",
    "        one_hot[0][2] = 1\n",
    "    orth = np.zeros((len(row[2]), 4))\n",
    "    for i in range(len(row[2])):\n",
    "        c = row[2][i]\n",
    "        if c == 'A':\n",
    "            orth[i][0] = 1\n",
    "        elif c == 'C':\n",
    "            orth[i][1] = 1\n",
    "        elif c == 'G':\n",
    "            orth[i][2] = 1\n",
    "        elif c == 'T':\n",
    "            orth[i][3] = 1\n",
    "        elif c == 'D':\n",
    "            orth[i][0] = 1/3.\n",
    "            orth[i][2] = 1/3.\n",
    "            orth[i][3] = 1/3.\n",
    "        elif c == 'N':\n",
    "            orth[i][0] = 1/4.\n",
    "            orth[i][1] = 1/4.\n",
    "            orth[i][2] = 1/4.\n",
    "            orth[i][3] = 1/4.\n",
    "        elif c == 'S':\n",
    "            orth[i][1] = 1/2.\n",
    "            orth[i][2] = 1/2.\n",
    "        elif c == 'R':\n",
    "            orth[i][0] = 1/2.\n",
    "            orth[i][2] = 1/2.\n",
    "    return orth, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 4, 60) (3190, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(raw_data.shape[0]):\n",
    "    xi, yi = getInstance(raw_data[i])\n",
    "    x.append(xi)\n",
    "    y.append(yi)\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# Shuffle dataset since it's unevenly distributed\n",
    "shuffle_index = np.random.permutation(len(x))\n",
    "x = x[shuffle_index]\n",
    "y = y[shuffle_index]\n",
    "\n",
    "# Conv1D expects channels first\n",
    "x = np.swapaxes(x, 1, 2)\n",
    "print (x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, Dropout, MaxPooling1D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()\n",
    "K.set_learning_phase(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(8, 3, input_shape=(None, 60), padding='same', name='conv1'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(16, 3, padding='same', name='conv2'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dense(3, name='fc1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2871 samples, validate on 319 samples\n",
      "Epoch 1/30\n",
      "2871/2871 [==============================] - 4s 1ms/step - loss: 0.9931 - acc: 0.5131 - val_loss: 0.8256 - val_acc: 0.6583\n",
      "Epoch 2/30\n",
      "2871/2871 [==============================] - 1s 206us/step - loss: 0.6208 - acc: 0.7844 - val_loss: 0.4016 - val_acc: 0.8871\n",
      "Epoch 3/30\n",
      "2871/2871 [==============================] - 1s 176us/step - loss: 0.3112 - acc: 0.9094 - val_loss: 0.2267 - val_acc: 0.9310\n",
      "Epoch 4/30\n",
      "2871/2871 [==============================] - 0s 163us/step - loss: 0.1968 - acc: 0.9446 - val_loss: 0.1753 - val_acc: 0.9373\n",
      "Epoch 5/30\n",
      "2871/2871 [==============================] - 0s 161us/step - loss: 0.1477 - acc: 0.9606 - val_loss: 0.1473 - val_acc: 0.9530\n",
      "Epoch 6/30\n",
      "2871/2871 [==============================] - 0s 150us/step - loss: 0.1193 - acc: 0.9666 - val_loss: 0.1414 - val_acc: 0.9498\n",
      "Epoch 7/30\n",
      "2871/2871 [==============================] - 0s 139us/step - loss: 0.0999 - acc: 0.9725 - val_loss: 0.1373 - val_acc: 0.9498\n",
      "Epoch 8/30\n",
      "2871/2871 [==============================] - 0s 138us/step - loss: 0.0877 - acc: 0.9784 - val_loss: 0.1212 - val_acc: 0.9592\n",
      "Epoch 9/30\n",
      "2871/2871 [==============================] - 0s 152us/step - loss: 0.0778 - acc: 0.9829 - val_loss: 0.1301 - val_acc: 0.9561\n",
      "Epoch 10/30\n",
      "2871/2871 [==============================] - 0s 139us/step - loss: 0.0702 - acc: 0.9822 - val_loss: 0.1236 - val_acc: 0.9624\n",
      "Epoch 11/30\n",
      "2871/2871 [==============================] - 0s 129us/step - loss: 0.0643 - acc: 0.9854 - val_loss: 0.1302 - val_acc: 0.9561\n",
      "Epoch 12/30\n",
      "2871/2871 [==============================] - 0s 119us/step - loss: 0.0559 - acc: 0.9885 - val_loss: 0.1384 - val_acc: 0.9467\n",
      "Epoch 13/30\n",
      "2871/2871 [==============================] - 0s 128us/step - loss: 0.0504 - acc: 0.9889 - val_loss: 0.1280 - val_acc: 0.9561\n",
      "Epoch 14/30\n",
      "2871/2871 [==============================] - 0s 112us/step - loss: 0.0467 - acc: 0.9892 - val_loss: 0.1286 - val_acc: 0.9687\n",
      "Epoch 15/30\n",
      "2871/2871 [==============================] - 0s 125us/step - loss: 0.0423 - acc: 0.9934 - val_loss: 0.1301 - val_acc: 0.9561\n",
      "Epoch 16/30\n",
      "2871/2871 [==============================] - 0s 110us/step - loss: 0.0395 - acc: 0.9934 - val_loss: 0.1376 - val_acc: 0.9561\n",
      "Epoch 17/30\n",
      "2871/2871 [==============================] - 0s 102us/step - loss: 0.0361 - acc: 0.9934 - val_loss: 0.1493 - val_acc: 0.9530\n",
      "Epoch 18/30\n",
      "2871/2871 [==============================] - 0s 123us/step - loss: 0.0315 - acc: 0.9948 - val_loss: 0.1414 - val_acc: 0.9530\n",
      "Epoch 19/30\n",
      "2871/2871 [==============================] - 0s 98us/step - loss: 0.0293 - acc: 0.9969 - val_loss: 0.1787 - val_acc: 0.9467\n",
      "Epoch 20/30\n",
      "2871/2871 [==============================] - 0s 95us/step - loss: 0.0270 - acc: 0.9962 - val_loss: 0.1549 - val_acc: 0.9498\n",
      "Epoch 21/30\n",
      "2871/2871 [==============================] - 0s 88us/step - loss: 0.0252 - acc: 0.9962 - val_loss: 0.1741 - val_acc: 0.9530\n",
      "Epoch 22/30\n",
      "2871/2871 [==============================] - 0s 92us/step - loss: 0.0228 - acc: 0.9976 - val_loss: 0.1691 - val_acc: 0.9498\n",
      "Epoch 23/30\n",
      "2871/2871 [==============================] - 0s 76us/step - loss: 0.0214 - acc: 0.9965 - val_loss: 0.2034 - val_acc: 0.9404\n",
      "Epoch 24/30\n",
      "2871/2871 [==============================] - 0s 80us/step - loss: 0.0198 - acc: 0.9976 - val_loss: 0.1689 - val_acc: 0.9467\n",
      "Epoch 25/30\n",
      "2871/2871 [==============================] - 0s 94us/step - loss: 0.0188 - acc: 0.9979 - val_loss: 0.1870 - val_acc: 0.9498\n",
      "Epoch 26/30\n",
      "2871/2871 [==============================] - 0s 77us/step - loss: 0.0170 - acc: 0.9993 - val_loss: 0.1740 - val_acc: 0.9498\n",
      "Epoch 27/30\n",
      "2871/2871 [==============================] - 0s 84us/step - loss: 0.0157 - acc: 0.9990 - val_loss: 0.1718 - val_acc: 0.9467\n",
      "Epoch 28/30\n",
      "2871/2871 [==============================] - 0s 102us/step - loss: 0.0160 - acc: 0.9990 - val_loss: 0.1886 - val_acc: 0.9498\n",
      "Epoch 29/30\n",
      "2871/2871 [==============================] - 0s 99us/step - loss: 0.0138 - acc: 0.9990 - val_loss: 0.2208 - val_acc: 0.9436\n",
      "Epoch 30/30\n",
      "2871/2871 [==============================] - 0s 87us/step - loss: 0.0130 - acc: 0.9990 - val_loss: 0.2153 - val_acc: 0.9498\n"
     ]
    }
   ],
   "source": [
    "callbacks = []\n",
    "#callbacks.append(TensorBoard(write_graph=False, histogram_freq=1, write_grads=False, write_images=False))\n",
    "\n",
    "model.fit(x, y, epochs=30, batch_size=32, validation_split=0.1, shuffle=True, callbacks=callbacks)\n",
    "K.set_learning_phase(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualizeLayer(layer_name, filter_index):\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    print (layer_output)\n",
    "    #loss = K.mean(layer_output[:, :, filter_index])\n",
    "    loss = K.mean(model.output[:, :, filter_index])\n",
    "    input_img = model.input\n",
    "    # compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    #grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "    # we start from a gray image with some noise\n",
    "    input_img_data = np.zeros((1, 4, 60))\n",
    "    input_img_data[:] = 0.25\n",
    "    # run gradient ascent for 20 steps\n",
    "    step = 1\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        \n",
    "        #print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            # break\n",
    "            pass\n",
    "    input_img_data[0] /= np.linalg.norm(input_img_data[0], 1, axis=0)\n",
    "    input_img_data = np.clip(input_img_data, 0, 1)\n",
    "    plt.imshow(input_img_data[0], cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_15/truediv:0\", shape=(?, ?, 3), dtype=float32)\n",
      "Tensor(\"conv2_4/add:0\", shape=(?, ?, 16), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAABPCAYAAAAJIxbdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1746a474b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (model.output)\n",
    "visualizeLayer('conv2', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 3)\n",
      "Tensor(\"gradients_55/conv1_4/convolution/ExpandDims_grad/Reshape:0\", shape=(?, ?, 60), dtype=float32)\n",
      "Label is 2\n",
      "['G', 'G', 'C', 'C', 'C', 'T', 'A', 'G', 'T', 'A', 'G', 'C', 'A', 'G', 'C', 'C', 'A', 'T', 'A', 'C', 'A', 'G', 'G', 'A', 'G', 'C', 'T', 'G', 'G', 'G', 'G', 'A', 'A', 'G', 'G', 'G', 'G', 'G', 'C', 'C', 'T', 'C', 'T', 'G', 'G', 'G', 'G', 'C', 'T', 'G', 'A', 'C', 'C', 'A', 'G', 'G', 'C', 'G', 'A', 'C']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3YAAAAxCAYAAACWGDvEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17466d4f940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 1\n",
    "print (model.output.shape)\n",
    "loss = K.mean(model.output[:, :, np.argmax(y[index])])\n",
    "input_img = model.input\n",
    "grads = K.gradients(loss, input_img)[0]\n",
    "print (grads)\n",
    "iterate = K.function([input_img], [loss, grads])\n",
    "input_img_data = np.zeros((1, 4, 60))\n",
    "input_img_data[0,:] = x[index]\n",
    "loss_value, grads_value = iterate([input_img_data])\n",
    "\n",
    "print (\"Label is \" + str(np.argmax(y[index])))\n",
    "g = grads_value[0] * x[index]\n",
    "g = np.sum(g, axis=0).reshape(1, 60)\n",
    "def sequenceFromOneHot(s):\n",
    "    s = s.T\n",
    "    l = []\n",
    "    for i in range(len(s)):\n",
    "        if s[i][0] == 1.:\n",
    "            l.append('A')\n",
    "        elif s[i][1] == 1.:\n",
    "            l.append('C')\n",
    "        elif s[i][2] == 1.:\n",
    "            l.append('G')\n",
    "        elif s[i][3] == 1.:\n",
    "            l.append('T')\n",
    "        elif s[i][0] == 1/3. and s[i][2] == 1/3. and s[i][3] == 1/3.:\n",
    "            l.append('D')\n",
    "        elif s[i][0] == 1/4. and s[i][1] == 1/4. and s[i][2] == 1/4. and s[i][3] == 1/4.:\n",
    "            l.append('N')\n",
    "        elif s[i][1] == 1/2. and s[i][2] == 1/2.:\n",
    "            l.append('S')\n",
    "        elif s[i][0] == 1/2. and s[i][2] == 1/2.:\n",
    "            l.append('R')\n",
    "            \n",
    "    print(l)\n",
    "    return l\n",
    "plt.xticks( np.arange(60), sequenceFromOneHot(x[index]) )\n",
    "plt.imshow(g, cmap='viridis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 8]\n"
     ]
    }
   ],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print (fig_size)\n",
    "fig_size[0] = 15\n",
    "fig_size[1] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
