{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the splice data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'splice.data'\n",
    "with open(fname) as f:\n",
    "    content = f.readlines()\n",
    "content = [x.strip().split(',') for x in content]\n",
    "for l in content:\n",
    "    for i in range(len(l)):\n",
    "        l[i] = l[i].strip()\n",
    "raw_data = np.array(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Given one 'row' of data, constructs an input and output out of it\n",
    "def getInstance(row):\n",
    "    one_hot = np.zeros((1, 3))\n",
    "    label = row[0]\n",
    "    if label == 'EI':\n",
    "        one_hot[0][0] = 1\n",
    "    elif label == 'IE':\n",
    "        one_hot[0][1] = 1\n",
    "    else:\n",
    "        one_hot[0][2] = 1\n",
    "    orth = np.zeros((len(row[2]), 4))\n",
    "    for i in range(len(row[2])):\n",
    "        c = row[2][i]\n",
    "        if c == 'A':\n",
    "            orth[i][0] = 1\n",
    "        elif c == 'C':\n",
    "            orth[i][1] = 1\n",
    "        elif c == 'G':\n",
    "            orth[i][2] = 1\n",
    "        elif c == 'T':\n",
    "            orth[i][3] = 1\n",
    "        elif c == 'D':\n",
    "            orth[i][0] = 1/3.\n",
    "            orth[i][2] = 1/3.\n",
    "            orth[i][3] = 1/3.\n",
    "        elif c == 'N':\n",
    "            orth[i][0] = 1/4.\n",
    "            orth[i][1] = 1/4.\n",
    "            orth[i][2] = 1/4.\n",
    "            orth[i][3] = 1/4.\n",
    "        elif c == 'S':\n",
    "            orth[i][1] = 1/2.\n",
    "            orth[i][2] = 1/2.\n",
    "        elif c == 'R':\n",
    "            orth[i][0] = 1/2.\n",
    "            orth[i][2] = 1/2.\n",
    "    return orth, one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3190, 4, 60) (3190, 1, 3)\n"
     ]
    }
   ],
   "source": [
    "x = []\n",
    "y = []\n",
    "for i in range(raw_data.shape[0]):\n",
    "    xi, yi = getInstance(raw_data[i])\n",
    "    x.append(xi)\n",
    "    y.append(yi)\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "# Shuffle dataset since it's unevenly distributed\n",
    "shuffle_index = np.random.permutation(len(x))\n",
    "x = x[shuffle_index]\n",
    "y = y[shuffle_index]\n",
    "\n",
    "# Conv1D expects channels first\n",
    "x = np.swapaxes(x, 1, 2)\n",
    "print (x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Conv1D, Dropout, MaxPooling1D\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.backend import clear_session\n",
    "clear_session()\n",
    "K.set_learning_phase(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(8, 3, input_shape=(None, 60), padding='same', name='conv1'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(16, 3, padding='same', name='conv2'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Dense(3, name='fc1'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2871 samples, validate on 319 samples\n",
      "Epoch 1/30\n",
      "2871/2871 [==============================] - 4s 1ms/step - loss: 0.9931 - acc: 0.5131 - val_loss: 0.8256 - val_acc: 0.6583\n",
      "Epoch 2/30\n",
      "2871/2871 [==============================] - 1s 206us/step - loss: 0.6208 - acc: 0.7844 - val_loss: 0.4016 - val_acc: 0.8871\n",
      "Epoch 3/30\n",
      "2871/2871 [==============================] - 1s 176us/step - loss: 0.3112 - acc: 0.9094 - val_loss: 0.2267 - val_acc: 0.9310\n",
      "Epoch 4/30\n",
      "2871/2871 [==============================] - 0s 163us/step - loss: 0.1968 - acc: 0.9446 - val_loss: 0.1753 - val_acc: 0.9373\n",
      "Epoch 5/30\n",
      "2871/2871 [==============================] - 0s 161us/step - loss: 0.1477 - acc: 0.9606 - val_loss: 0.1473 - val_acc: 0.9530\n",
      "Epoch 6/30\n",
      "2871/2871 [==============================] - 0s 150us/step - loss: 0.1193 - acc: 0.9666 - val_loss: 0.1414 - val_acc: 0.9498\n",
      "Epoch 7/30\n",
      "2871/2871 [==============================] - 0s 139us/step - loss: 0.0999 - acc: 0.9725 - val_loss: 0.1373 - val_acc: 0.9498\n",
      "Epoch 8/30\n",
      "2871/2871 [==============================] - 0s 138us/step - loss: 0.0877 - acc: 0.9784 - val_loss: 0.1212 - val_acc: 0.9592\n",
      "Epoch 9/30\n",
      "2871/2871 [==============================] - 0s 152us/step - loss: 0.0778 - acc: 0.9829 - val_loss: 0.1301 - val_acc: 0.9561\n",
      "Epoch 10/30\n",
      "2871/2871 [==============================] - 0s 139us/step - loss: 0.0702 - acc: 0.9822 - val_loss: 0.1236 - val_acc: 0.9624\n",
      "Epoch 11/30\n",
      "2871/2871 [==============================] - 0s 129us/step - loss: 0.0643 - acc: 0.9854 - val_loss: 0.1302 - val_acc: 0.9561\n",
      "Epoch 12/30\n",
      "2871/2871 [==============================] - 0s 119us/step - loss: 0.0559 - acc: 0.9885 - val_loss: 0.1384 - val_acc: 0.9467\n",
      "Epoch 13/30\n",
      "2871/2871 [==============================] - 0s 128us/step - loss: 0.0504 - acc: 0.9889 - val_loss: 0.1280 - val_acc: 0.9561\n",
      "Epoch 14/30\n",
      "2871/2871 [==============================] - 0s 112us/step - loss: 0.0467 - acc: 0.9892 - val_loss: 0.1286 - val_acc: 0.9687\n",
      "Epoch 15/30\n",
      "2871/2871 [==============================] - 0s 125us/step - loss: 0.0423 - acc: 0.9934 - val_loss: 0.1301 - val_acc: 0.9561\n",
      "Epoch 16/30\n",
      "2871/2871 [==============================] - 0s 110us/step - loss: 0.0395 - acc: 0.9934 - val_loss: 0.1376 - val_acc: 0.9561\n",
      "Epoch 17/30\n",
      "2871/2871 [==============================] - 0s 102us/step - loss: 0.0361 - acc: 0.9934 - val_loss: 0.1493 - val_acc: 0.9530\n",
      "Epoch 18/30\n",
      "2871/2871 [==============================] - 0s 123us/step - loss: 0.0315 - acc: 0.9948 - val_loss: 0.1414 - val_acc: 0.9530\n",
      "Epoch 19/30\n",
      "2871/2871 [==============================] - 0s 98us/step - loss: 0.0293 - acc: 0.9969 - val_loss: 0.1787 - val_acc: 0.9467\n",
      "Epoch 20/30\n",
      "2871/2871 [==============================] - 0s 95us/step - loss: 0.0270 - acc: 0.9962 - val_loss: 0.1549 - val_acc: 0.9498\n",
      "Epoch 21/30\n",
      "2871/2871 [==============================] - 0s 88us/step - loss: 0.0252 - acc: 0.9962 - val_loss: 0.1741 - val_acc: 0.9530\n",
      "Epoch 22/30\n",
      "2871/2871 [==============================] - 0s 92us/step - loss: 0.0228 - acc: 0.9976 - val_loss: 0.1691 - val_acc: 0.9498\n",
      "Epoch 23/30\n",
      "2871/2871 [==============================] - 0s 76us/step - loss: 0.0214 - acc: 0.9965 - val_loss: 0.2034 - val_acc: 0.9404\n",
      "Epoch 24/30\n",
      "2871/2871 [==============================] - 0s 80us/step - loss: 0.0198 - acc: 0.9976 - val_loss: 0.1689 - val_acc: 0.9467\n",
      "Epoch 25/30\n",
      "2871/2871 [==============================] - 0s 94us/step - loss: 0.0188 - acc: 0.9979 - val_loss: 0.1870 - val_acc: 0.9498\n",
      "Epoch 26/30\n",
      "2871/2871 [==============================] - 0s 77us/step - loss: 0.0170 - acc: 0.9993 - val_loss: 0.1740 - val_acc: 0.9498\n",
      "Epoch 27/30\n",
      "2871/2871 [==============================] - 0s 84us/step - loss: 0.0157 - acc: 0.9990 - val_loss: 0.1718 - val_acc: 0.9467\n",
      "Epoch 28/30\n",
      "2871/2871 [==============================] - 0s 102us/step - loss: 0.0160 - acc: 0.9990 - val_loss: 0.1886 - val_acc: 0.9498\n",
      "Epoch 29/30\n",
      "2871/2871 [==============================] - 0s 99us/step - loss: 0.0138 - acc: 0.9990 - val_loss: 0.2208 - val_acc: 0.9436\n",
      "Epoch 30/30\n",
      "2871/2871 [==============================] - 0s 87us/step - loss: 0.0130 - acc: 0.9990 - val_loss: 0.2153 - val_acc: 0.9498\n"
     ]
    }
   ],
   "source": [
    "callbacks = []\n",
    "#callbacks.append(TensorBoard(write_graph=False, histogram_freq=1, write_grads=False, write_images=False))\n",
    "\n",
    "model.fit(x, y, epochs=30, batch_size=32, validation_split=0.1, shuffle=True, callbacks=callbacks)\n",
    "K.set_learning_phase(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualizeLayer(layer_name, filter_index):\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    print (layer_output)\n",
    "    loss = K.mean(layer_output[:, :, filter_index])\n",
    "    #loss = K.mean(model.output[:, :, filter_index])\n",
    "    input_img = model.input\n",
    "    # compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    #grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "    # we start from a gray image with some noise\n",
    "    input_img_data = np.zeros((1, 4, 60))\n",
    "    input_img_data[:] = 0.25\n",
    "    # run gradient ascent for 20 steps\n",
    "    step = 1\n",
    "    for i in range(20):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "        \n",
    "        #print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            # break\n",
    "            pass\n",
    "    input_img_data[0] /= np.linalg.norm(input_img_data[0], 1, axis=0)\n",
    "    input_img_data = np.clip(input_img_data, 0, 1)\n",
    "    plt.imshow(input_img_data[0], cmap='viridis')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"activation_15/truediv:0\", shape=(?, ?, 3), dtype=float32)\n",
      "Tensor(\"conv2_4/add:0\", shape=(?, ?, 16), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArwAAABPCAYAAAAJIxbdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABQajS8AAAAKLX/Bru8ktaYOGDRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x174694105f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (model.output)\n",
    "visualizeLayer('conv2', 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 3)\n",
      "Tensor(\"gradients_9/conv1_3/convolution/ExpandDims_grad/Reshape:0\", shape=(?, ?, 60), dtype=float32)\n",
      "[[[ -3.38530335e-05  -1.09222510e-05   2.17180641e-05  -2.13855019e-05\n",
      "    -4.87073248e-06  -4.81878233e-05   2.93413032e-05   1.91459767e-05\n",
      "    -4.82541182e-05  -2.63182301e-05  -4.55569534e-07   1.26191480e-05\n",
      "    -3.03119068e-05  -2.52373720e-05  -5.45610055e-05  -1.24207745e-05\n",
      "    -4.88756705e-05  -6.36362602e-05  -1.84765850e-05  -4.03819504e-05\n",
      "    -7.96740351e-05  -6.88788350e-05  -5.47513300e-05   7.14944508e-06\n",
      "    -4.08492451e-05  -1.94330714e-05   2.39002311e-05  -1.03636601e-04\n",
      "     2.21989379e-04  -1.05729683e-04  -3.31019692e-05  -2.43304239e-05\n",
      "     1.62793076e-05   6.87954744e-05  -6.57456403e-05  -1.86824946e-05\n",
      "     1.54897862e-05  -1.74521520e-05  -4.96585972e-06  -2.55416380e-05\n",
      "    -8.39160748e-06  -2.17099023e-05   1.70015792e-05  -7.65475033e-06\n",
      "    -1.63778132e-05  -4.13466023e-06   3.93033370e-05  -2.74644335e-05\n",
      "    -8.18195440e-06  -1.06482585e-05   3.03062643e-06  -2.03163436e-05\n",
      "    -2.02493575e-05  -3.05535323e-05   1.09629273e-05  -2.18047026e-05\n",
      "     2.73299102e-05   5.54389044e-05  -1.16228084e-05  -1.30117533e-05]\n",
      "  [  2.60763500e-05   4.64004042e-05   1.69929772e-05   4.48320279e-05\n",
      "     3.99808450e-05   3.77484757e-05   9.12954420e-06   2.01112762e-05\n",
      "    -3.19975952e-05  -8.77915318e-06   5.99311534e-05   5.75835693e-05\n",
      "     3.05703797e-05   3.07662158e-05  -5.03431329e-06   3.41816922e-05\n",
      "     3.23999520e-05   7.93223808e-06   2.34182880e-05  -3.16281075e-05\n",
      "     3.68693145e-05  -2.21916343e-05  -1.31368533e-05  -3.91990070e-05\n",
      "     1.56992719e-05  -4.23342281e-05  -2.14376869e-05   1.11819987e-04\n",
      "    -1.36241099e-04  -4.08927881e-05   4.36975388e-05  -8.48758427e-05\n",
      "    -3.17044141e-05   2.24085161e-05  -6.31701732e-06  -5.60077351e-05\n",
      "     3.64536390e-06   3.95220104e-06   3.14574863e-05  -1.78050614e-05\n",
      "     1.69405484e-05  -2.22684357e-05   1.74189991e-05  -2.84419821e-05\n",
      "     7.30511965e-06   2.82033143e-05   2.36707892e-05   1.94435088e-05\n",
      "     2.29718917e-05   1.75517398e-05  -8.74154921e-06  -1.98297494e-05\n",
      "     2.63087531e-06  -8.18860462e-06  -3.43058746e-05   3.47264140e-05\n",
      "    -3.13743622e-05   3.39589023e-05   2.32952316e-05  -3.09220268e-05]\n",
      "  [ -1.91248037e-05  -4.79773462e-06  -3.62991741e-05  -3.43172142e-05\n",
      "    -2.33410265e-05   1.00531151e-05  -1.22663259e-05   7.67025085e-06\n",
      "    -7.10622908e-06  -5.08894627e-05   4.90053208e-06  -9.11164716e-06\n",
      "    -4.05301762e-07  -2.06329278e-05  -1.98527541e-05  -3.08155613e-05\n",
      "     8.02965587e-06  -3.00859083e-05  -4.58905051e-05   1.37810766e-05\n",
      "    -2.04058815e-05  -2.45113661e-05  -3.79090998e-05  -7.44736462e-05\n",
      "    -1.06159110e-04  -5.03042902e-05  -1.28204310e-05  -9.62044069e-05\n",
      "    -2.30063844e-04   2.88736017e-04   2.34621039e-05   5.49478209e-05\n",
      "    -2.29682992e-05  -2.83359295e-05   3.39679318e-05   3.82602484e-05\n",
      "    -3.09439238e-05   7.78267895e-06   4.60491574e-05  -3.08012204e-07\n",
      "     1.28725751e-05  -1.31343259e-05   1.31406196e-05  -4.90209131e-05\n",
      "     1.46211933e-05   1.34028505e-05   1.72612708e-05   3.69980407e-05\n",
      "    -1.17563386e-05   1.42532363e-05  -9.35247499e-07   2.36639175e-06\n",
      "     1.85610988e-05  -2.43594332e-06  -4.86429872e-06  -5.00203259e-06\n",
      "     8.00893977e-05   2.67010073e-05   3.97650729e-06   5.26327021e-05]\n",
      "  [  2.78224052e-05   9.44619387e-08   1.51172217e-05   2.14621105e-05\n",
      "     2.87631628e-05   3.05384528e-05   1.43467860e-05  -2.45848787e-06\n",
      "    -2.11026163e-05   3.50601404e-05   3.49703005e-05   2.95387981e-05\n",
      "     2.43006180e-05   1.60102772e-05  -1.41301880e-05   1.84191813e-05\n",
      "     2.46799082e-05   1.58975417e-05   7.46780715e-05   2.06218629e-05\n",
      "     3.57408426e-05   6.08965602e-05   5.58836764e-05   1.24693488e-05\n",
      "     5.14927815e-05   4.62359203e-05  -1.83647262e-05   9.09971204e-05\n",
      "    -1.36401330e-04  -8.94511322e-05   7.10851964e-07   5.45388903e-05\n",
      "    -1.36835906e-05   8.48462150e-06  -5.06427496e-05   2.14222928e-06\n",
      "     2.66405095e-05  -1.21990442e-05  -2.06768291e-05   1.97440531e-05\n",
      "    -7.27847873e-06   9.24541655e-06  -1.44082069e-05  -1.07114274e-05\n",
      "    -3.79488702e-05   4.52879931e-07   6.43379508e-06  -1.92828174e-05\n",
      "    -1.32895875e-05  -7.21082688e-06  -1.00152674e-05  -3.05849135e-05\n",
      "     2.27185847e-05   1.85225254e-05  -1.51669774e-05  -9.19423564e-06\n",
      "    -3.83944498e-05  -3.87289801e-05   1.23289592e-05  -2.99696912e-05]]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print (model.output.shape)\n",
    "loss = K.mean(model.output[:, :, np.argmax(y[index])])\n",
    "input_img = model.input\n",
    "grads = K.gradients(loss, input_img)[0]\n",
    "print (grads)\n",
    "iterate = K.function([input_img], [loss, grads])\n",
    "input_img_data = np.zeros((1, 4, 60))\n",
    "input_img_data[0,:] = x[index]\n",
    "loss_value, grads_value = iterate([input_img_data])\n",
    "print (grads_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12, 8]\n"
     ]
    }
   ],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "print (fig_size)\n",
    "fig_size[0] = 12\n",
    "fig_size[1] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
